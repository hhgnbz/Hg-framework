# 优化

- 将单独lru算法实现改成多种算法可选（容易实现且lru, lfu都是经典算法，方便顺便考察算法能力） 
- 将http通信改为rpc通信提高网络通信效率（方便引出rpc相关问题） 
- 细化锁的粒度来提高并发性能 
- 实现热点互备来避免hot key频繁请求网络影响性能（groupcache中提出的优化） 
- 加入etcd进行分布式节点的监测实现节点的动态管理（能拓展出大量分布式问题，etcd作为常见组件在面试中也很能聊） 
- 加入缓存过期机制，自动清理超时缓存

# 常见问题

- 这个项目有什么优点? 
    1. 写性能优秀：磁盘内顺序写入，减少磁盘寻道消耗，实现高吞吐量写入
    2. 读性能：本身为内存储存key的索引，通过索引访问磁盘，磁盘IO消耗较大，但可以配置将k-v存储至内存中(类似Redis)，减少磁盘IO的消耗。
    3. 多数据结构存储：bitcask模型中，内存数据结构为哈希表，不支持复杂查询，项目中支持了*String/Hash/List/Set/ZSet*数据结构，操作性增强。
    4. 支持过期时间：内存中维护map，记录每个key的过期时间，过期信息持久化到单独的文件中，启动即加载至内存中。
- 介绍一下bitcask模型 
    1. 日志形式存储，顺序写模型，简单版的LSM树。
    2. active文件：示例实际上为系统上一个文件夹，数据文件在磁盘上顺序写入，文件大小到达限制后，将其变为只读，重开新文件写入新数据，每次只有一个文件可进行写入动作。
    3. entry：文件中的每个数据，包含*key大小/value大小/k-v值/操作类型/校验和等*
    4. 更新/删除操作：追加一条记录至key索引对应文件中。
    5. 内存内存储key的索引，每次操作后更新内存。
    6. 读取操作：访问内存中key对应索引，访问磁盘对应文件取值。
    7. 数据文件冗余：通过merge操作，遍历所有数据文件，将无效信息删除。
- 了解LSM树么 
    1. LSM 树的全称为结构化合并树，其设计目标是提供比传统的 B+ 树更好的写性能。
    2. LSM 树将对数据的修改增量保持在内存中，达到指定的大小限制后将这些修改操作批量写入磁盘(由此提升了写性能)，是一种基于硬盘的数据结构。 
    3. 在LSM 树中，通过将磁盘的随机写转化为顺序写来提高写性能，而付出的代价就是牺牲部分读性能和写放大问题(B+树同样有写放大的问题)。
    4. LSM 相比B+ 树能提高写性能的本质原因是:外存的随机读写都要慢于顺序读写，无论磁盘还是SSD。磁盘中会定期做 merge 操作，合并成一棵大树，以优化读性能。
    5. LSM树的优势在于有效地规避了磁盘随机写入问题，但读取时可能需要访问较多的磁盘文件。
- 内存映射（mmap）是什么？ 
    1. mmap 是一种将文件映射到内存的方法，实现文件的磁盘地址和进程虚拟地址空间中的一段虚拟地址的一一映射关系。 
    2. 可以在某个进程中通过操作这一段映射的内存，实现对文件的读写等操作，修改了这一段内存的内容，文件对应位置的内容也会同步修改，而获取这一段内存的内容，也相当于读取文件对应位置的内容。
- 做项目的过程中有没有什么自己的想法？ 
- merge操作如何进行？还可以继续优化么？
    1. merge 要重新组织磁盘中的数据，回收磁盘空间，当回收的时候整个数据库操作会被阻塞，因此要选择一个合适的时机进行这个操作，比如在关闭数据库前。
    2. 遍历五种类型的已封存的文件信息(以 map 形式存在)，判断是否有哪种类型的文件数量超过了闻值，如果都没有超过则不需要回收。
    3. 回收时先新建临时目录，用于创建新的数据文件，然后进行加锁，避免产生其他数据操作。
    4. 因为有五种不同类型的数据文件，而这五种文件也互不干扰，因此可以分别用五个goroutine 来执行回收操作。用sync.Map 创建并发安全的临时封存文件索引，之后遍历每种数据类型，以下以string类型为例。 
    5. 先判断当前类型的文件数量是否达到了闻值，如果没有达到则不整理该类型文件。然后遍历当前类型的所有封存文件，遍历每个文件中的entry记录，来判断当前的entry 是否有效。
    6. 将所有有效的entry放到一个新的entry数组中后，将这些有效的entry重新写入到一批数据文件中，最后因为磁盘中文件的位置发生了变更，因此也要更新内存索引中记录的文件信息，再更新数据库配置即完成全部操作。
- 服务端客户端命令行如何实现的？ 
- 项目中用到了跳表，为什么用，怎么实现的？ 
- 跳表重点问题（从选择跳表到跳表实现中的细节，如果自己写跳表一定要搞懂）
- 为什么要使用 etcd，怎么用的？ 
- Raft 算法 
- etcd 是如何保证强一致性的呢 
- etcd分布式锁实现的基础机制是怎样的 
- 能说一说用 etcd 时它处理请求的流程是怎样的吗 
- 什么是一致性哈希？
    1. 开辟一个2^32的空间，数字首尾相连形成环
    2. 计算各个节点(一般用节点名/节点编号/节点地址计算)的hash，放入环对应位置
    3. 计算每个key的hash，放入环中
    4. 顺时针寻找第一个节点，就是key对应存放的节点
- 为什么在项目中要使用一致性哈希？ 
    1. 分布式结构中，若某个节点没有保存查找的缓存值，节点面临无法确定下一步查找节点的难题。
    2. 若简单用Hash(key)后取模，节点个数不变情况下，可以稳定获取到缓存值。但若节点个数改变，简单取模会导致大量缓存无法被查询到，需要到数据源进行查询，容易造成缓存雪崩。
- 如何保证一致性哈希算法的有效性？ 
- 一致性哈希算法中的虚拟节点是什么？它们的作用是什么？ 
    1. 是什么：为每个节点增加几个子节点，但这些子节点不是真实的，而是在哈希表中维护真实节点与子节点的映射关系，key hash查找到子节点(虚拟节点)，虚拟节点再查找到真实节点。
    2. 作用：防止节点较少时，数据容易向某个节点倾斜，导致节点间负载不均。
- 虚拟节点怎么实现的？查找目标 key 的过程是怎样的？
    1. 假设 1 个真实节点对应 3 个虚拟节点，那么 peer1 对应的虚拟节点是 peer1-1、 peer1-2、 peer1-3（通常以添加编号的方式实现），其余节点也以相同的方式操作。
    2. 计算虚拟节点的 Hash 值，放置在环上。 
    3. 计算 key 的 Hash 值，在环上顺时针寻找到应选取的虚拟节点，例如是 peer2-1，那么就对应真实节点 peer2。
- 去设计一个分布式缓存系统要从哪些方面考虑?
    1. 考虑本地缓存
       1. 数据存储方式：用什么数据结构，简单哈希表或类似redis多种数据类型
       2. 缓存策略：FIFO/LFU/LRU等
       3. 过期时间：是否要添加过期时间，过期时间是否要配合缓存策略一起使用
       4. 缓存失效：缓存失效或缓存未命中的处理方式
       5. 并发访问：并发访问时如何保证系统安全和稳定
    2. 考虑分布式
       1. 负载均衡：多个节点均衡分配，均匀处理请求
       2. 节点通信：多个节点之间如何通信
       3. 缓存一致性：同个数据在多个节点同时存在，当一个节点数据更新，如何通知另外节点及时更新
       4. 系统可用性：分布式环境下，某个节点发生故障或网络中断，如何设计容错机制和故障恢复策略
- 缓存雪崩，击穿，穿透分别是什么，如何应对？ 
     1. 缓存雪崩：某一时刻大量缓存过期或故障导致缓存宕机，同时大量用户请求，这些请求会直接访问到数据库，从而导致数据库压力剧增，严重的导致数据库宕机，导致一系列连锁反应。
     2. 缓存击穿：热点数据过期，导致大量请求穿过缓存访问数据库，数据库很容易被高并发的请求击垮。击穿可以看成是雪崩的一个子集。
     3. 缓存穿透：用户访问缓存、数据库中都没有的数据，先访问缓存后到数据库，由于数据库中不存在数据，缓存也不会更新，后续相同请求多次进入，导致数据库面临高并发压力。
     4. 应对措施：
        1. 使用集群，保证服务的高可用。
        2. 分级缓存，用带过期机制的本地缓存保存热点数据，代替一部分的分布式缓存系统功能。
        3. 建立合理的熔断以及限流保护机制，有效避免缓存雪崩。
        4. **singleFlight机制** #TODO
- 你的项目中如何应对缓存雪崩和缓存击穿问题？ 
    1. 实现了singleFlight机制：在多个并发请求触发的回调操作中，只有第一个回调方法被执行，其他请求阻塞等待第一个回调方法执行完成后，直接提取结果，保证一时间内只有一个方法被执行，达到防止缓存击穿的目的。
- 了解的缓存淘汰策略有哪些？
- etcd 相关问题 (如果用到了 etcd 一定要准备相关问题)
- 刚刚说到了redis，为什么redis的zset用跳表实现而不是红黑树？ 
- 跳表索引的动态更新是怎样做的？ 
- 跳表的高度控制策略是怎样的？ 
- 既然跳表的平衡是随机算法控制的，那如何保证O(logn)的复杂度？